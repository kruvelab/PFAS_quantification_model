install.packages("patRoon")
??patRoon
patRoon::newProject()
setwd("~/GitHub/PFOA_semi_quant_HS")
#setwd("/GitHub/PFAS_semi_quant_HS")
source("code/functions.R")
library(caTools)
library(tidyverse)
library(caret)
library(plotly)
## ---- Reading in LC-MS data of calibration solutions ----
Orbitrap_dataset_raw = read_excel_allsheets(filename = "data/Batch 1 Semi Quant w frag.xlsx")
Orbitrap_dataset_raw = Orbitrap_dataset_raw %>%
group_by(Compound) %>%
mutate(Theoretical_amt = case_when(
Filename == "2020071205-cal21" ~ mean(Theoretical_amt[Filename=="2020071205-cal22"]),
TRUE ~ Theoretical_amt))%>%
ungroup() %>%
filter(Theoretical_amt != "NaN")
## ---- Reading in SMILES for calibration compounds, removing NAs and adducts, mono PAPs, HFPO-DA ----
SMILES_data = read_SMILES(filename = "data/Smiles_for_Target_PFAS_semicolon.csv",
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
## ---- Joining all collected data to one tibble, removing missing values, calculating slopes ----
data = Orbitrap_dataset_raw %>%
left_join(SMILES_data) %>%
drop_na(SMILES) %>%
mutate(RT = as.numeric(RT),
area_IC = Area*IC,
Theoretical_conc_uM = Theoretical_amt/Molecular_weight) %>%
group_by(SMILES, Compound) %>%
summarize(slope = linear_regression(area_IC, Theoretical_conc_uM)$slope,
RT = mean(RT)) %>%
ungroup()
data = add_mobile_phase_composition(data = data,
eluent_file_name = "data/eluent.csv")
## ---- Converting slopes to logIE with PFOS as anchor ----
training = anchoring(data_to_be_anchored = data,
data_containing_anchor = "data/IE_training_data/190714_negative_model_logIE_data.csv")
## ---- Calculating PaDEL descriptors to all compounds based on SMILES ----
data_all_binded = PaDEL_original(training)
## ---- Cleaning data ----
data_clean = cleaning_data(data_all_binded)
## ---- Training the model with all data ----
logIE_pred_model = training_logIE_pred_model(data = data_clean,
split = 0.8)
knitr::opts_chunk$set(echo = TRUE)
library(caret) #machine learning workflow for model training with cross-validation
knitr::opts_chunk$set(echo = TRUE)
library(caTools) #sample splitting to training and test/validation set is from this package
library(tidyverse) #tidyverse helps us to write concise code, is your best friend when processing any data in R
setwd("C:/Users/HelenSepman/OneDrive - Kruvelab/Helen_phd/Courses/Chemometrics/lab3_1")
#importing the data
dataset =  read_delim('Cao2015_SI.csv',
delim = ',',
locale = locale(decimal_mark = '.'),
col_names = TRUE,
trim_ws = TRUE) %>%
na.omit() #omitting rows with missing values
View(dataset)
dataset = dataset %>%
relocate(c(cid, compound, smiles, RT), .after = last_col())
?caTools
?leaps
??leaps
?caret
??caret
??leaps
library(caret) #machine learning workflow for model training with cross-validation
library(caTools) #sample splitting to training and test/validation set is from this package
library(leaps) #library for step wise multilinear regression
library(tidyverse) #tidyverse helps us to write concise code, is your best friend when processing any data in R
#importing the data
dataset =  read_delim('Cao2015_SI.csv',
delim = ',',
locale = locale(decimal_mark = '.'),
col_names = TRUE,
trim_ws = TRUE) %>%
na.omit() #omitting rows with missing values
#importing the data
dataset =  read_delim('Cao2015_SI.csv',
delim = ',',
locale = locale(decimal_mark = '.'),
col_names = TRUE,
trim_ws = TRUE) %>%
na.omit() #omitting rows with missing values
View(dataset)
setwd("C:/Users/HelenSepman/OneDrive - Kruvelab/Helen_phd/Courses/Chemometrics/lab3_1")
library(caret) #machine learning workflow for model training with cross-validation
library(caTools) #sample splitting to training and test/validation set is from this package
library(leaps) #library for step wise multilinear regression
library(tidyverse) #tidyverse helps us to write concise code, is your best friend when processing any data in R
#importing the data
dataset =  read_delim('Cao2015_SI.csv',
delim = ',',
locale = locale(decimal_mark = '.'),
col_names = TRUE,
trim_ws = TRUE) %>%
na.omit() #omitting rows with missing values
View(dataset)
??caret
library(caTools) #sample splitting to training and test/validation set is from this package
library(leaps) #library for step wise multilinear regression
library(tidyverse) #tidyverse helps us to write concise code, is your best friend when processing any data in R
setwd("C:/Users/HelenSepman/OneDrive - Kruvelab/Helen_phd/Courses/Chemometrics/lab3_1")
#importing the data
dataset =  read_delim('Cao2015_SI.csv',
delim = ',',
locale = locale(decimal_mark = '.'),
col_names = TRUE,
trim_ws = TRUE) %>%
na.omit() #omitting rows with missing values
View(dataset)
