#population-n = 10000------
per_cent_faulty = 10
n_all = 10000
n_sample = 10
n_faulty = per_cent_faulty * n_all / 100
n_ok = n_all - n_faulty
population = c(rep("ok", n_ok),
rep("faulty", n_faulty)) %>%
sample() #shuffle the order of the items
sample_summary = tibble()
for (i in 1:100) {
sample_this = sample(population, n_sample) %>%
as.tibble()
sample_this = sample_this %>%
group_by(value) %>%
summarise(per_cent_faulty_in_sample = n() / n_sample *100) %>%
ungroup() %>%
filter(value == "faulty")
if (dim(sample_this)[1] == 0) {
sample_this = tibble(value = "faulty",
per_cent_faulty_in_sample = 0)
}
sample_summary = sample_summary %>%
bind_rows(sample_this)
}
histogram = ggplot(data = sample_summary) +
geom_histogram(mapping = aes(x = per_cent_faulty_in_sample),
binwidth = 5,
fill = "blue") +
xlim(-5, 50) +
ylim(0, 100) +
labs(x = "% faulty items")
histogram
#population-n = 100------
per_cent_faulty = 10
n_all = 100
n_sample = 10
n_faulty = per_cent_faulty * n_all / 100
n_ok = n_all - n_faulty
population = c(rep("ok", n_ok),
rep("faulty", n_faulty)) %>%
sample() #shuffle the order of the items
sample_summary = tibble()
for (i in 1:100) {
sample_this = sample(population, n_sample) %>%
as.tibble()
sample_this = sample_this %>%
group_by(value) %>%
summarise(per_cent_faulty_in_sample = n() / n_sample *100) %>%
ungroup() %>%
filter(value == "faulty")
if (dim(sample_this)[1] == 0) {
sample_this = tibble(value = "faulty",
per_cent_faulty_in_sample = 0)
}
sample_summary = sample_summary %>%
bind_rows(sample_this)
}
histogram = ggplot(data = sample_summary) +
geom_histogram(mapping = aes(x = per_cent_faulty_in_sample),
binwidth = 5,
fill = "blue") +
xlim(-5, 50) +
ylim(0, 100) +
labs(x = "% faulty items")
histogram
#write your code here
dataset = read_excel("PFAS_blood_level_pre-study.xlsx") %>%
clean_names()
knitr::opts_chunk$set(echo = TRUE)
#library(janitor)
#library(readxl)
library(tidyverse) #tidyverse helps us to write concise code, is your best friend when processing any data in R
#write your code here
dataset = read_excel("PFAS_blood_level_pre-study.xlsx") %>%
clean_names()
dataset = read_excel("PFAS_blood_level_pre-study.xlsx"
)
?clean_names
??clean_names
knitr::opts_chunk$set(echo = TRUE)
#write your code here
dataset = read_excel("PFAS_blood_level_pre-study.xlsx") %>%
clean_names()
library(janitor)
library(readxl)
library(tidyverse) #tidyverse helps us to write concise code, is your best friend when processing any data in R
#write your code here
dataset = read_excel("PFAS_blood_level_pre-study.xlsx") %>%
clean_names()
ggplot(data = dataset,
mapping = aes(x = pfas_ng_g)) +
geom_histogram() +
geom_density()
ggplot(data = dataset,
mapping = aes(x = pfas_ng_g)) +
geom_histogram() +
geom_density() +
scale_x_log10()
ggplot(data = dataset,
mapping = aes(x = pfas_ng_g)) +
geom_histogram() +
geom_density()
ggplot(data = dataset,
mapping = aes(x = pfas_ng_g)) +
#geom_histogram() +
geom_density()
ggplot(data = dataset,
mapping = aes(x = pfas_ng_g)) +
#geom_histogram() +
geom_density() +
scale_x_log10()
library(rcdk)
admin = "C:/Users/HelenSepman/OneDrive - Kruvelab/Helen_phd/projects_measurements/Lisa_PCL/03_data_analysis/standards/"
setwd(admin)
#metadata
metadata = read_delim("spikes/standards_metadata_retentiontime.xlsx")
library(readxl)
#metadata
metadata = read_excel("spikes/standards_metadata_retentiontime.xlsx")
#metadata
metadata = read_excel("standards_metadata_retentiontime.xlsx")
View(metadata)
admin = "C:/Users/HelenSepman/OneDrive - Kruvelab/Helen_phd/projects_measurements/Lisa_PCL/03_data_analysis/standards/"
setwd(admin)
#metadata
metadata = read_excel("standards_metadata_retentiontime.xlsx")
View(metadata)
#file here
table = read_delim("measurements_MSDIAL_SIRIUS/230313WWTP_SWS/MSDIAL_results/alignment_files/Area_allfiles.txt", skip = 4)
admin = "C:/Users/HelenSepman/OneDrive - Kruvelab/Helen_phd/projects_measurements/Lisa_PCL/"
setwd(admin)
#file here
table = read_delim("01_experimental_data/measurements_MSDIAL_SIRIUS/230313WWTP_SWS/MSDIAL_results/alignment_files/Area_allfiles.txt", skip = 4)
#finding matches with spikes
library(tidyverse)
#file here
table = read_delim("01_experimental_data/measurements_MSDIAL_SIRIUS/230313WWTP_SWS/MSDIAL_results/alignment_files/Area_allfiles.txt", skip = 4)
View(table)
#metadata
metadata = read_excel("03_data_analysis/standards/standards_metadata_retentiontime.xlsx") %>%
drop_na(retention_time)
table_here = table %>%
#drop_na(`MS/MS spectrum`) %>%
select(`Average Mz`, `Average Rt(min)`) %>%
rename(average_mz = `Average Mz`,
average_rt = `Average Rt(min)`) %>%
#select(average_mz) %>%
unique() %>%
left_join(metadata %>%
select(spike_mz, retention_time), by = character()) %>%
mutate(delta_mz = abs(average_mz - spike_mz),
delta_rt = abs(average_rt - retention_time))
View(table_here)
table_here = table %>%
#drop_na(`MS/MS spectrum`) %>%
select(`Average Mz`, `Average Rt(min)`) %>%
rename(average_mz = `Average Mz`,
average_rt = `Average Rt(min)`) %>%
#select(average_mz) %>%
unique() %>%
left_join(metadata %>%
select(spike_mz, retention_time), by = character()) %>%
mutate(delta_mz = abs(average_mz - spike_mz),
delta_rt = abs(average_rt - retention_time)) %>%
filter(delta_mz < 0.001,
delta_rt < 0.5)
length(unique(table_here$spike_mz))
table_here = table %>%
drop_na(`MS/MS spectrum`) %>%
select(`Average Mz`, `Average Rt(min)`) %>%
rename(average_mz = `Average Mz`,
average_rt = `Average Rt(min)`) %>%
#select(average_mz) %>%
unique() %>%
left_join(metadata %>%
select(spike_mz, retention_time), by = character()) %>%
mutate(delta_mz = abs(average_mz - spike_mz),
delta_rt = abs(average_rt - retention_time)) %>%
filter(delta_mz < 0.001,
delta_rt < 0.5)
length(unique(table_here$spike_mz))
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant/"
setwd(admin)
source("02_code/functions.R")
library(caTools)
library(tidyverse)
library(caret)
library(plotly)
library(cowplot)
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/01_data_for_modelling/Batch 1 Semi Quant w frag.xlsx")
cal_filename_smiles <- paste0(admin,"/data_for_modelling/Smiles_for_Target_PFAS_semicolon.csv")
sus_filename_data <- paste0(admin,"/04_results/new_suspects_quant/20210810_Suspect_Screening_TF.xlsx")
sus_filename_smiles <- paste0(admin,"/results/new_suspects_quant/suspects_smiles_updated_semicolon2.csv")
logIE_pred_model <- readRDS(paste0(admin,"/03_models/230619_logIE_model_withPFAS_allData.Rdata"))
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/01_data_for_modelling/Batch 1 Semi Quant w frag.xlsx")
cal_filename_smiles <- paste0(admin,"/01_data_for_modelling/Smiles_for_Target_PFAS_semicolon.csv")
sus_filename_data <- paste0(admin,"/04_results/new_suspects_quant/20210810_Suspect_Screening_TF.xlsx")
sus_filename_smiles <- paste0(admin,"/results/new_suspects_quant/suspects_smiles_updated_semicolon2.csv")
logIE_pred_model <- readRDS(paste0(admin,"/03_models/230619_logIE_model_withPFAS_allData.Rdata"))
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = "data_for_modelling/eluent.csv",
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/01_data_for_modelling/Batch 1 Semi Quant w frag.xlsx")
cal_filename_smiles <- paste0(admin,"/01_data_for_modelling/Smiles_for_Target_PFAS_semicolon.csv")
sus_filename_data <- paste0(admin,"/04_results/new_suspects_quant/20210810_Suspect_Screening_TF.xlsx")
sus_filename_smiles <- paste0(admin,"/results/new_suspects_quant/suspects_smiles_updated_semicolon2.csv")
logIE_pred_model <- readRDS(paste0(admin,"/03_models/230619_logIE_model_withPFAS_allData.Rdata"))
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = "data_for_modelling/eluent.csv",
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/01_data_for_modelling/IE_training_data/Batch 1 Semi Quant w frag.xlsx")
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = "data_for_modelling/eluent.csv",
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant/05_suspect_quantification"
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
getwd()
source("/02_code/functions.R")
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant/"
source("/02_code/functions.R")
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source("/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/05_suspect_quantification/Batch 1 Semi Quant w frag.xlsx")
cal_filename_smiles <- paste0(admin,"/Smiles_for_Target_PFAS_semicolon.csv")
sus_filename_data <- paste0(admin,"/20210810_Suspect_Screening_TF.xlsx")
sus_filename_smiles <- paste0(admin,"/suspects_smiles_updated_semicolon2.csv")
logIE_pred_model <- readRDS(paste0(admin,"/03_models/230619_logIE_model_withPFAS_allData.Rdata"))
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = "/eluent.csv",
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source("/02_code/functions.R")
source("~/02_code/functions.R")
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source("~/02_code/functions.R")
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
getwd()
# Change the admin directory
admin <- "C:/Users/HelenSepman/OneDrive - Kruvelab/Documents/GitHub/PFOA_semi_quant"
setwd(admin)
source(paste0(admin,"/02_code/functions.R"))
library(caTools)
library(tidyverse)
library(caret)
library(plotly)
library(cowplot)
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/05_suspect_quantification/Batch 1 Semi Quant w frag.xlsx")
#### When calibrants and suspects are in separate TraceFinder and SMILES files ####
cal_filename_data <-  paste0(admin,"/05_suspect_quantification/Batch 1 Semi Quant w frag.xlsx")
cal_filename_smiles <- paste0(admin,"/05_suspect_quantification/Smiles_for_Target_PFAS_semicolon.csv")
sus_filename_data <- paste0(admin,"/05_suspect_quantification/20210810_Suspect_Screening_TF.xlsx")
sus_filename_smiles <- paste0(admin,"/05_suspect_quantification/suspects_smiles_updated_semicolon2.csv")
logIE_pred_model <- readRDS(paste0(admin,"/03_models/230619_logIE_model_withPFAS_allData.Rdata"))
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = "/05_suspect_quantification/eluent.csv",
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = paste0(admin, "/05_suspect_quantification/eluent.csv"),
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
filename_eluent = paste0(admin, "/05_suspect_quantification/eluent.csv"
)
pred_model =  logIE_pred_model
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP")
organic_modifier = "MeCN"
pH.aq. = 7.0
NH4 = 1
additive = "ammoniumacetate"
additive_concentration_mM = 2
instrument = "Orbitrap"
source = "ESI"
analysis_data_cal <- read_excel_allsheets(cal_filename_data)
SMILES_data_cal <- read_SMILES(cal_filename_smiles, compounds_to_be_removed_as_list)
#suspects data from analysis, filtered by smiles
analysis_data_sus <- read_excel_allsheets(sus_filename_data)
SMILES_data_sus <- read_SMILES(sus_filename_smiles)
analysis_data_sus <- analysis_data_sus %>%
mutate(Theoretical_amt = replace(Theoretical_amt , grepl("NaN", Theoretical_amt, fixed = TRUE), NA)) %>%
left_join(SMILES_data_sus) %>%
drop_na(SMILES)
analysis_data = analysis_data_cal %>%
mutate(Theoretical_amt = replace(Theoretical_amt , grepl("NaN", Theoretical_amt, fixed = TRUE), NA)) %>%
left_join(SMILES_data_cal) %>%
drop_na(SMILES) %>%
bind_rows(analysis_data_sus) %>%
mutate(RT = as.numeric(RT),
area_IC = Area*IC,
Theoretical_conc_uM = Theoretical_amt/Molecular_weight)
analysis_data_descr <- analysis_data %>%
group_by(Compound) %>%
mutate(slope = linear_regression(area_IC, Theoretical_conc_uM)$slope,
intercept = linear_regression(area_IC, Theoretical_conc_uM)$intercept,
RT = mean(RT)) %>%
ungroup()
plot_calgraph <- ggplot() +
geom_point(data = analysis_data_descr,
mapping = aes(x = Theoretical_conc_uM,
y = area_IC)) +
facet_wrap(~ Compound, scales = "free") +
theme_classic()
plot_calgraph
analysis_data_descr = add_mobile_phase_composition(data = analysis_data_descr,
eluent_file_name = filename_eluent,
organic_modifier = organic_modifier,
pH.aq. = pH.aq.,
NH4 = NH4,
additive = additive,
additive_concentration_mM = additive_concentration_mM,
instrument = instrument,
source = source)
analysis_data_descr <- PaDEL_original(analysis_data_descr)
standards = analysis_data_descr
SMILES_list = standards %>%
select(SMILES) %>%
unique() %>%
na.omit() %>%
mutate(Name = row_number())
standards = standards %>%
left_join(SMILES_list)
write_delim(SMILES_list %>% select(SMILES) %>% unique(),
"SMILES.smi",
col_names = FALSE)
command = "java -jar PaDEL-Descriptor/PaDEL-Descriptor.jar -dir" #file name where they will be calculated
command_final = paste(command, "SMILES.smi", "-file", "descs_calc.csv", "-2d", sep =" ") #makes text for command prompt
javaOutput = system(command_final, intern = TRUE) #goes into commant prompt
#PaDEL saves the descriptors to the local folder
descs = read_delim("descs_calc.csv",
delim = ",",
col_names = TRUE)
descs = descs %>%
group_by(Name) %>%
mutate(Name = str_split(Name, pattern = "_")[[1]][length(str_split(Name, pattern = "_")[[1]])]) %>%
ungroup() %>%
mutate(Name = as.integer(Name))
descs <- descs[order(descs$Name),]
descs = descs %>%
left_join(standards) %>%
select(colnames(standards), everything()) %>%
select(-Name)
write_delim(descs,
"data_for_modelling/descs_calc.csv",
delim = ",")
write_delim(descs,
"01_data_for_modelling/descs_calc.csv",
delim = ",")
analysis_data_descr <- PaDEL_original(analysis_data_descr)
PaDEL_original = function(standards) {
SMILES_list = standards %>%
select(SMILES) %>%
unique() %>%
na.omit() %>%
mutate(Name = row_number())
standards = standards %>%
left_join(SMILES_list)
write_delim(SMILES_list %>% select(SMILES) %>% unique(),
"SMILES.smi",
col_names = FALSE)
command = "java -jar PaDEL-Descriptor/PaDEL-Descriptor.jar -dir" #file name where they will be calculated
command_final = paste(command, "SMILES.smi", "-file", "descs_calc.csv", "-2d", sep =" ") #makes text for command prompt
javaOutput = system(command_final, intern = TRUE) #goes into commant prompt
#PaDEL saves the descriptors to the local folder
descs = read_delim("descs_calc.csv",
delim = ",",
col_names = TRUE)
descs = descs %>%
group_by(Name) %>%
mutate(Name = str_split(Name, pattern = "_")[[1]][length(str_split(Name, pattern = "_")[[1]])]) %>%
ungroup() %>%
mutate(Name = as.integer(Name))
descs <- descs[order(descs$Name),]
descs = descs %>%
left_join(standards) %>%
select(colnames(standards), everything()) %>%
select(-Name)
write_delim(descs,
"01_data_for_modelling/descs_calc.csv",
delim = ",")
return(descs)
}
analysis_data_descr <- PaDEL_original(analysis_data_descr)
analysis_data_descr <- analysis_data_descr %>%
mutate(logIE_predicted = predict(pred_model$model, newdata = analysis_data_descr))
# lm function to find RF of suspect compound
linMod <- lm(logIE_predicted ~ log10(slope), data = analysis_data_descr %>%
drop_na(slope))
# Plot measured vs predicted
plot_predictedIE_slope = ggplot() +
geom_point(data = analysis_data_descr,
mapping = aes(log10(slope),
logIE_predicted,
text = Compound),
color = "black",
alpha = 0.5,
size = 3) +
theme_classic() +
geom_abline(slope = summary(linMod)$coefficients[2], intercept = summary(linMod)$coefficients[1]) +
geom_abline(slope = summary(linMod)$coefficients[2], intercept = 1+summary(linMod)$coefficients[1]) +
geom_abline(slope = summary(linMod)$coefficients[2], intercept = -1+summary(linMod)$coefficients[1]) +
xlab("log10(measured RF)") +
ylab("log10(predicted IE)")
# Find RF values from predicted IEs to all non-calibrant analytes
analytes_concentrations <- analysis_data_descr %>%
# filter(is.na(slope)) %>%
mutate(slope_pred = 10^((logIE_predicted - summary(linMod)$coefficients[1])/summary(linMod)$coefficients[2])) %>%
mutate(conc_pred_uM = area_IC/slope_pred) %>%
mutate(conc_pred_pg_uL = conc_pred_uM*Molecular_weight) %>%
select(colnames(analysis_data), slope_pred, conc_pred_uM, conc_pred_pg_uL)
plot_predicted_theoretical_conc <- ggplot() +
geom_point(data = analytes_concentrations %>%
drop_na(Theoretical_conc_uM) %>%
group_by(Compound, Theoretical_conc_uM) %>%
mutate(conc_pred_uM = mean(conc_pred_uM)) %>%
ungroup(),
mapping = aes(Theoretical_conc_uM, conc_pred_uM,
color = Compound)) +
geom_abline(slope = 1, intercept = 0) +
scale_y_log10(limits = c(10^-5, 10^0)) +
scale_x_log10(limits = c(10^-5, 10^0)) +
geom_abline(slope = 1, intercept = 0) +
geom_abline(slope = 1, intercept = 1) +
geom_abline(slope = 1, intercept = -1) +
theme(aspect.ratio = 1) +
theme_classic()
ggplotly(plot_predicted_theoretical_conc)
#Return list with data, plot
data_predicted = list("all_calibration_plots" = plot_calgraph,
"plot_predictedIE_slope" = plot_predictedIE_slope,
"plot_predicted_theoretical_conc" = plot_predicted_theoretical_conc,
"data" = analytes_concentrations)
concentrations_pred <- concentration_forAnalytes_model_cal_separateFile(cal_filename_data,
cal_filename_smiles,
sus_filename_data,
sus_filename_smiles,
filename_eluent = paste0(admin, "/05_suspect_quantification/eluent.csv"),
pred_model =  logIE_pred_model,
compounds_to_be_removed_as_list = c("HFPO-DA", "MeFOSE", "EtFOSE", "PFHpS-br", "PFPeS", "PFHpS", "PFNS", "PFPeDA", "10:2 mono PAP", "4:2 mono PAP", "6:2 mono PAP", "8:2 mono PAP"))
concentrations_pred_conc <- concentrations_pred$data
concentrations_pred_conc <- concentrations_pred_conc %>%
select(-c(IC, Molecular_weight, area_IC)) %>%
rename(Predicted_RF = slope_pred)
# Calibration plots to all cal compounds - can check if something needs to be removed that does not have a nice cal graph
concentrations_pred$all_calibration_plots
# Model calibration - response factors and ionization efficiencies for calibration compounds
ggplotly(concentrations_pred$plot_predictedIE_slope)
# Model results based on calibration compounds - predicted vs real concentrations (uM)
ggplotly(concentrations_pred$plot_predicted_theoretical_conc)
